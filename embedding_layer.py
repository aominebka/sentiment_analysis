# -*- coding: utf-8 -*-
"""embedding_layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OGJqKLf2kIbfWlQd-xzAxgVBk6PDD5Q2
"""

import numpy as np
np.random.seed(0)
from keras.models import Model
from keras.layers import Dense, Input, Dropout, LSTM, Activation
from keras.layers.embeddings import Embedding
from keras.preprocessing import sequence
from keras.initializers import glorot_uniform

def read_glove_vecs(glove_file):
    with open(glove_file, 'r',encoding='UTF-8') as f:
        words = set()
        word_to_vec_map = {}
        for line in f:
            line = line.strip().split()
            curr_word = line[0]
            words.add(curr_word)
            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)
        
        i = 1
        words_to_index = {}
        index_to_words = {}
        for w in sorted(words):
            words_to_index[w] = i
            index_to_words[i] = w
            i = i + 1
  
        m = len(words_to_index)
        for i in range(1,m+1):
          word=index_to_words[i]
          if word_to_vec_map[word].shape[0]!=100:
              word_to_vec_map[word]=np.concatenate((word_to_vec_map[word],np.zeros(1)))
    return words_to_index, index_to_words, word_to_vec_map



def sentense_to_indices(x,maxlen,word_to_index):
  # x is a list of text and have shape: (m,)
  y=np.zeros((len(x),maxlen))
  for i in range(len(x)):
      z=x[i].split()
      for idx, word in enumerate(z[:maxlen]):
        try:
          
          y[i,idx]=word_to_index[word]
        except:
          y[i,idx]=1999   #word_to_index['<unknown>']=1999
  return y







